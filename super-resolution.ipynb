{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "Initial quick solve with frozen env failed.  Unfreezing env and trying again.\n",
      "Solving environment: | ^C\n",
      "failed\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "%matplotlib inline\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pnsn(target, ref):\n",
    "    target = target.astype('float')\n",
    "    ref = ref.astype('float')\n",
    "    diff= (target - ref).flatten('C')\n",
    "    rls = math.sqrt(np.mean(diff**2))\n",
    "    return 20*math.log10(255/rls)\n",
    "def mse(target, ref):\n",
    "    err =  np.sum((target.astype('float') - ref.astype('float'))**2)\n",
    "    err/= float(target.shape[0]*target.shape[1])\n",
    "    return err\n",
    "def scores(target,ref):\n",
    "    score = []\n",
    "    score.append(pnsn(target, ref))\n",
    "    score.append(mse(target,ref))\n",
    "    score.append(ssim(target, ref, multichannel=True))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedata(path, factor):\n",
    "    for file in list(os.listdir(path)):\n",
    "        img = cv2.imread(str(path + '/' + file))\n",
    "        \n",
    "        h,v,c = img.shape\n",
    "        newheight = h/factor\n",
    "        new_weight = v/factor\n",
    "        #make lower resolution\n",
    "        img = cv2.resize(img, (round(newheight), round(new_weight)), interpolation= cv2.INTER_LINEAR )\n",
    "        #resize image\n",
    "        img = cv2.resize(img, (v,h), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        print('low resolution image {}'.format(file))\n",
    "        cv2.imwrite(str('images/'+ file), img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low resolution image barbara.bmp\n",
      "low resolution image zebra.bmp\n",
      "low resolution image head_GT.bmp\n",
      "low resolution image man.bmp\n",
      "low resolution image monarch.bmp\n",
      "low resolution image ppt3.bmp\n",
      "low resolution image comic.bmp\n",
      "low resolution image bird_GT.bmp\n",
      "low resolution image woman_GT.bmp\n",
      "low resolution image pepper.bmp\n",
      "low resolution image lenna.bmp\n",
      "low resolution image baboon.bmp\n",
      "low resolution image baby_GT.bmp\n",
      "low resolution image flowers.bmp\n",
      "low resolution image foreman.bmp\n",
      "low resolution image butterfly_GT.bmp\n",
      "low resolution image face.bmp\n"
     ]
    }
   ],
   "source": [
    "preparedata('src/',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barbara.bmp\n",
      "PNSR: 25.125\n",
      "MSE : 599.44\n",
      "SSIM: 0.79327\n",
      "\n",
      "zebra.bmp\n",
      "PNSR: 26.655\n",
      "MSE : 421.44\n",
      "SSIM: 0.87192\n",
      "\n",
      "head_GT.bmp\n",
      "PNSR: 31.021\n",
      "MSE : 154.22\n",
      "SSIM: 0.80111\n",
      "\n",
      "man.bmp\n",
      "PNSR: 27.226\n",
      "MSE : 369.45\n",
      "SSIM: 0.8215\n",
      "\n",
      "monarch.bmp\n",
      "PNSR: 29.431\n",
      "MSE : 222.38\n",
      "SSIM: 0.93703\n",
      "\n",
      "ppt3.bmp\n",
      "PNSR: 24.918\n",
      "MSE : 628.68\n",
      "SSIM: 0.92782\n",
      "\n",
      "comic.bmp\n",
      "PNSR: 23.204\n",
      "MSE : 932.93\n",
      "SSIM: 0.81668\n",
      "\n",
      "bird_GT.bmp\n",
      "PNSR: 32.897\n",
      "MSE : 100.12\n",
      "SSIM: 0.95336\n",
      "\n",
      "woman_GT.bmp\n",
      "PNSR: 28.699\n",
      "MSE : 263.21\n",
      "SSIM: 0.92828\n",
      "\n",
      "pepper.bmp\n",
      "PNSR: 29.889\n",
      "MSE : 200.1\n",
      "SSIM: 0.83579\n",
      "\n",
      "lenna.bmp\n",
      "PNSR: 31.473\n",
      "MSE : 138.95\n",
      "SSIM: 0.8461\n",
      "\n",
      "baboon.bmp\n",
      "PNSR: 22.208\n",
      "MSE : 1173.4\n",
      "SSIM: 0.64895\n",
      "\n",
      "baby_GT.bmp\n",
      "PNSR: 34.372\n",
      "MSE : 71.289\n",
      "SSIM: 0.9357\n",
      "\n",
      "flowers.bmp\n",
      "PNSR: 26.962\n",
      "MSE : 392.68\n",
      "SSIM: 0.86092\n",
      "\n",
      "foreman.bmp\n",
      "PNSR: 30.741\n",
      "MSE : 164.49\n",
      "SSIM: 0.93562\n",
      "\n",
      "butterfly_GT.bmp\n",
      "PNSR: 24.782\n",
      "MSE : 648.63\n",
      "SSIM: 0.87913\n",
      "\n",
      "face.bmp\n",
      "PNSR: 30.992\n",
      "MSE : 155.23\n",
      "SSIM: 0.80084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in list(os.listdir('images/')):\n",
    "    target = cv2.imread('images/{}'.format(file))\n",
    "    ref = cv2.imread('src/{}'.format(file))\n",
    "    score = scores(target, ref)\n",
    "    print('{}\\nPNSR: {:.5}\\nMSE : {:.5}\\nSSIM: {:.5}\\n'.format(file, score[0], score[1], score[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    SPCNN = Sequential()\n",
    "    SPCNN.add(Conv2D(filters=128, kernel_size=(9,9), kernel_initializer='glorot_uniform', padding='valid',activation='relu', use_bias=True, input_shape=(None, None,1)))\n",
    "    SPCNN.add(Conv2D(filters=64, kernel_size=(3,3), kernel_initializer='glorot_uniform',padding='same', activation='relu', use_bias=True))\n",
    "    SPCNN.add(Conv2D(filters=1, kernel_size=(5,5), kernel_initializer='glorot_uniform',activation='linear', padding='valid', use_bias=True))\n",
    "    adam = Adam(lr=0.0003)\n",
    "    SPCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'] )\n",
    "    return SPCNN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the image\n",
    "def dot_crop(img, crop):\n",
    "    tmpsz = img.shape\n",
    "    sz = tmpsz[0:2]\n",
    "    sz =sz - np.mod(sz,crop)\n",
    "    img = img[0:sz[0], 1:sz[1]]\n",
    "    return img\n",
    "def shave(img, shave):\n",
    "    img = img[shave:-shave, shave:-shave]\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(imgpath):\n",
    "    #load the pre traing \n",
    "    pscnn = model()\n",
    "    pscnn.load_weights('3051crop_weight_200.h5')\n",
    "    degred = cv2.imread(imgpath)\n",
    "    path, file = imgpath.split('/')\n",
    "    ref = cv2.imread('src/{}'.format(file))\n",
    "    #pre with dot_crop\n",
    "    degred = dot_crop(degred, 3)\n",
    "    ref = dot_crop(ref,3)\n",
    "    #convert to single channel\n",
    "    tmp = cv2.cvtColor(degred, cv2.COLOR_BGR2YCrCb)\n",
    "    #create simple slice\n",
    "    Y = np.zeros([1, tmp.shape[0], tmp.shape[1],1], dtype= 'float')\n",
    "    Y[0,:,:,0] = tmp[:,:,0].astype('float')/255\n",
    "    \n",
    "    #predict\n",
    "    pre = pscnn.predict(Y, batch_size=1)\n",
    "    \n",
    "    #change not right pixel\n",
    "    pre *= 255\n",
    "    pre[pre[:]>255]=255\n",
    "    pre[pre[:]<0]= 0\n",
    "    pre = pre.astype('uint8')\n",
    "    \n",
    "    #copy Y channel back to BGR\n",
    "    tmp = shave(tmp,6)\n",
    "    tmp[:,:,0]= pre[0,:,:,0]\n",
    "    \n",
    "    \n",
    "    output = cv2.cvtColor(tmp, cv2.COLOR_YCrCb2BGR)\n",
    "    ref = shave(ref.astype('uint8'), 6)\n",
    "    degred = shave(degred.astype('uint8'), 6)\n",
    "    cv2.imwrite('output/{}'.format(file),output)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training success image: barbara.bmp\n",
      "training success image: zebra.bmp\n",
      "training success image: head_GT.bmp\n",
      "training success image: man.bmp\n",
      "training success image: monarch.bmp\n",
      "training success image: ppt3.bmp\n",
      "training success image: comic.bmp\n",
      "training success image: bird_GT.bmp\n",
      "training success image: woman_GT.bmp\n",
      "training success image: pepper.bmp\n",
      "training success image: lenna.bmp\n",
      "training success image: baboon.bmp\n",
      "training success image: baby_GT.bmp\n",
      "training success image: flowers.bmp\n",
      "training success image: foreman.bmp\n",
      "training success image: butterfly_GT.bmp\n",
      "training success image: face.bmp\n",
      "Success image: 17/17\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for file in list(os.listdir('images/')):\n",
    "    train_model('images/{}'.format(file))\n",
    "    train_model('output/{}'.format(file))\n",
    "    print('training success image: {}'.format(file))\n",
    "    s +=1\n",
    "print('Success image: {}/{}'.format(s, len(os.listdir('images/'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
